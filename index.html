<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Xiaoyun Yuan</title>
  
  <meta name="author" content="Xiaoyun Yuan">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="imgs/th_icon_s.png">
  <style type="text/css">body {zoom:1.25;}</style>
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Xiaoyun Yuan, Ph.D.</name>
              </p>
              <p>I am a postdoctoral researcher (Supervisor: <a href="http://luvision.net">Dr. Lu Fang</a>) at <a href="http://luvision.net">Sigma lab</a>, Tsinghua University</a>,  where I work on Computational Photography. 
              </p>
              <p>We build the gigapixel dataset <a href="http://www.panda-dataset.com/">PANDA</a> for large scale human centric analysis. We are also holding competitions. Welcome !!!</p>
              <p>
                I got my PhD at Hong Kong University of Science and Technology, 2020. I did my bachelors at the University of Science and Technology of China.
              </p>
              <p style="text-align:center">
                xiaoyunyuan AT tsinghua.edu.cn &nbsp/&nbsp
                <!--<a href="data/JonBarron-CV.pdf">CV</a> &nbsp/&nbsp-->
                <!-- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp -->
                <a href="https://scholar.google.com/citations?user=MrEV0uwAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/xiaoyunyuan/">Linkedin</a> &nbsp/&nbsp
                <a href="https://github.com/yuanxy92">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="imgs/Xiaoyun.png"><img style="width:100%;max-width:100%" alt="profile photo" src="imgs/Xiaoyun.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <!-- News -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>News</heading>
            <p>
              Our paper <a href="https://doi.org/10.1117/12.2582652">"Mapping human brain function with massively parallel high-speed three-dimensional photoacoustic computed tomography"</a> won the <b>Best Paper Award</b> in Photons Plus Ultrasound: Imaging and Sensing 2021. <em>Mar 11, 2021</em>
            </p>
          </td>
        </tr>
      </tbody></table>

        <!-- Research -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Selected publications</heading>
              <p>
                I'm interested in Gigapixel Imaging, Optical Computing and Photoacoustic Imaging.
                Representative papers are listed.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:top">
              <div class="one">
                <img src='imgs/light.jpg' width="320">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:top">
              <a>
                <papertitle>A modular hierarchical array camera (cover article)</papertitle>
              </a>
              <br>
              <b>Xiaoyun Yuan*</b>, Mengqi Ji*, Jiamin Wu, David J. Brady, Qionghai Dai, Lu Fang
              <br>
              <b><em>Light: Science and Applications</em></b>, 2021  
              <br>
              <a href="https://www.nature.com/articles/s41377-021-00485-x">Paper</a> 
              <p>We develop an unstructured array camera system that adopts a hierarchical modular design with multiscale hybrid cameras composing different modules. Intelligent computations are designed to collaboratively operate along both intra- and intermodule pathways. This system can adaptively allocate imagery resources to dramatically reduce the hardware cost and possesses unprecedented flexibility, robustness, and versatility.
              </p>
            </td>
          </tr> 

          <tr>
            <td style="padding:20px;width:25%;vertical-align:top">
              <div class="one">
                <img src='imgs/nbme_pa.webp' width="320">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:top">
              <a>
                <papertitle>Massively parallel functional photoacoustic computed tomography of the human brain
                </papertitle>
              </a>
              <br>
              Shuai Na*, Jonathan J. Russin*, Li Lin*, <b>Xiaoyun Yuan*</b>, Peng Hu, Kay B. Jann, Lirong Yan, Konstantin Maslov, Junhui Shi, Danny J. Wang, Charles Y. Liu, Lihong V. Wang 
              <br>
              <b><em>Nature Biomedical Engineering</em></b>, 2021  
              <br>
              <a href="https://www.nature.com/articles/s41551-021-00735-8">Paper</a> 
              <p>Here, we show that massively parallel ultrasonic transducers arranged hemispherically around the human head can produce tomographic images of the brain with a 10-cm-diameter FOV and spatial and temporal resolutions of 350 µm and 2 s, respectively. Our findings establish the use of photoacoustic computed tomography for human brain imaging.
              </p>
            </td>
          </tr> 
          
          <tr>
            <td style="padding:20px;width:25%;vertical-align:top">
              <div class="one">
                <img src='imgs/multiscale_vr.jpg' width="320">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:top">
              <a>
                <papertitle>Multiscale-VR: Multiscale Gigapixel 3D Panoramic Videography for Virtual Reality</papertitle>
              </a>
              <br>
              Jianing Zhang*, Tianyi Zhu*, Anke Zhang*, <b>Xiaoyun Yuan*</b>, Zihan Wang, Sebastian Beetschen, Lan Xu, Xing Lin, Qionghai Dai, Lu Fang
              <br>
              <b><em>IEEE International Conference on Computational Photography (ICCP)</em></b>, 2020
              <br>
              <a href="https://ieeexplore.ieee.org/abstract/document/9105244">Paper</a>
              <p>In this work, we propose Multiscale-VR, a multiscale unstructured camera array computational imaging system for high-quality gigapixel 3D panoramic videography that creates the six-degree-of-freedom multiscale interactive VR content. The Multiscale-VR imaging system comprises scalable cylindrical-distributed global and local cameras, where global stereo cameras are stitched to cover 360° field-of-view, and unstructured local monocular cameras are adapted to the global camera for flexible high-resolution video streaming arrangement. 
              </p>
            </td>
          </tr> 

          <tr>
            <td style="padding:20px;width:25%;vertical-align:top">
              <div class="one">
                <img src='imgs/nc_pa.webp' width="320">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:top">
              <a>
                <papertitle>High-speed three-dimensional photoacoustic computed tomography for preclinical research and clinical translation</papertitle>
              </a>
              <br>
              Li Lin*, Peng Hu*, Xin Tong*, Shuai Na*, Rui Cao, <b>Xiaoyun Yuan</b>, David C Garrett, Junhui Shi, Konstantin Maslov, Lihong V Wang
              <br>
              <b><em>Nature Communications</em></b>, 2021  
              <br>
              <a href="https://www.nature.com/articles/s41467-021-21232-1">Paper</a> 
              <p>We developed a three-dimensional photoacoustic computed tomography (3D-PACT) system that features large imaging depth, scalable field of view with isotropic spatial resolution, high imaging speed, and superior image quality.
              </p>
            </td>
          </tr>

          <!--
          <tr>
            <td style="padding:20px;width:25%;vertical-align:top">
              <div class="one">
                <img src='imgs/ICCP_giga_2017.jpg' width="320">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:top">
              <a>
                <papertitle>Multiscale gigapixel video: A cross resolution image matching and warping approach</papertitle>
              </a>
              <br>
              <b>Xiaoyun Yuan</b>, Lu Fang, Qionghai Dai, David J Brady, Yebin Liu
              <br>
              <b><em>IEEE International Conference on Computational Photography (ICCP)</em></b>, 2017
              <br>
              <a href="https://ieeexplore.ieee.org/abstract/document/7951481">Paper</a>
              <p>We present a multi-scale camera array to capture and synthesize gigapixel videos in an efficient way. Our acquisition setup contains a reference camera with a short-focus lens to get a large field-of-view video and a number of unstructured long-focus cameras to capture local-view details. 
              </p>
            </td>
          </tr> 

          <tr>
            <td style="padding:20px;width:25%;vertical-align:top">
              <div class="one">
                <img src='imgs/TCSVT_glasses.jpg' width="320">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:top">
              <a>
                <papertitle>Magic glasses: from 2D to 3D</papertitle>
              </a>
              <br>
              <b>Xiaoyun Yuan*</b>, Difei Tang*, Yebin Liu, Qing Ling, Lu Fang
              <br>
              <b><em>IEEE Transactions on Circuits and Systems for Video Technology (TCSVT) </em></b>, 2016
              <br>
              <a href="https://ieeexplore.ieee.org/abstract/document/7457667">Paper</a>
              <p>This paper proposes a virtual 3D eyeglasses try-on system driven by a 2D Internet image of a human face wearing with a pair of eyeglasses. The main technical challenge of this system is the automatic 3D eyeglasses model reconstruction from the 2D glasses on a frontal human face. 
              </p>
            </td>
          </tr> 
        -->

          <tr>
            <td style="padding:20px;width:25%;vertical-align:top">
              <div class="one">
                <img src='imgs/crossnet.jpg' width="320">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:top">
              <a>
                <papertitle>Crossnet++: Cross-scale large-parallax warping for reference-based super-resolution</papertitle>
              </a>
              <br>
              Yang Tan*, Haitian Zheng*, Yinheng Zhu, <b>Xiaoyun Yuan</b>, Xing Lin, David Brady, Lu Fang
              <br>
              <b><em>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</em></b>, 2020
              <br>
              <a href="https://www.computer.org/csdl/journal/tp/5555/01/09099445/1k7oyvQ9LzO">Paper</a>
              <p>We present CrossNet++, an end-to-end network containing novel two-stage cross-scale warping modules. The stage I learns to narrow down the parallax distinctively with the strong guidance of landmarks and intensity distribution consensus. Then the stage II operates more fine-grained alignment and aggregation in feature domain to synthesize the final super-resolved image. To further address the large parallax, new hybrid loss functions comprising warping loss, landmark loss and super-resolution loss are proposed to regularize training and enable better convergence.
              </p>
            </td>
          </tr> 

          <tr>
            <td style="padding:20px;width:25%;vertical-align:top">
              <div class="one">
                <img src='imgs/panda.jpg' width="320">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:top">
              <a>
                <papertitle>Panda: A gigapixel-level human-centric video dataset</papertitle>
              </a>
              <br>
              Xueyang Wang*, Xiya Zhang*, Yinheng Zhu*, Yuchen Guo*, <b>Xiaoyun Yuan</b>, Liuyu Xiang, Zerun Wang, Guiguang Ding, David Brady, Qionghai Dai, Lu Fang
              <br>
              <b><em>Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (CVPR)</em></b>, 2020
              <br>
              <a href="https://openaccess.thecvf.com/content_CVPR_2020/html/Wang_PANDA_A_Gigapixel-Level_Human-Centric_Video_Dataset_CVPR_2020_paper.html">Paper</a> /
              <a href="http://www.panda-dataset.com/">Project page</a> 
              <p>PANDA is the first gigaPixel-level humAN-centric viDeo dAtaset, for large-scale, long-term, and multi-object visual analysis. The videos in PANDA were captured by a gigapixel camera and cover real-world large-scale scenes with both wide field-of-view (~1km^2 area) and high resolution details (~gigapixel-level/frame). The scenes may contain 4k head counts with over 100× scale variation. PANDA provides enriched and hierarchical ground-truth annotations, including 15,974.6k bounding boxes, 111.8k fine-grained attribute labels, 12.7k trajectories, 2.2k groups and 2.9k interactions.
              </p>
            </td>
          </tr> 


        </tbody></table>

        <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Service</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>
            <td width="75%" valign="center">
              <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair, CVPR 2021</a>
              <br><br>
              <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
              <br><br>
              <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
            </td>
          </tr>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/cs188.jpg" alt="cs188">
            </td>
            <td width="75%" valign="center">
              <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor, CS188 Spring 2011</a>
              <br>
              <br>
              <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor, CS188 Fall 2010</a>
              <br>
              <br>
              <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd Edition</a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        </tbody></table>
      </td>
    </tr>
  </table> -->
  <script type="text/javascript" src="//rf.revolvermaps.com/0/0/8.js?i=5g1be4nc2m6&amp;m=0&amp;c=ff0000&amp;cr1=ffffff&amp;f=arial&amp;l=33" async="async"></script>


</body>

</html>
